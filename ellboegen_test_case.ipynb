{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import foehnix\n",
    "\n",
    "ellboegen = pd.read_csv('data/ellboegen.csv', delimiter=';', skipinitialspace=True)\n",
    "sattelberg = pd.read_csv('data/sattelberg.csv', delimiter=';', skipinitialspace=True)\n",
    "\n",
    "data = pd.merge(ellboegen, sattelberg,on='timestamp', how='outer', suffixes=('', '_crest'), sort=True)\n",
    "data.index = pd.to_datetime(data.timestamp, unit='s')\n",
    "\n",
    "train=data.iloc[:-10].copy()\n",
    "test=data.iloc[-10:].copy()\n",
    "\n",
    "train['diff_t'] = train['t_crest'] + 10.27 - train['t']\n",
    "\n",
    "ddfilter= {'dd': [43, 223], 'dd_crest': [90, 270]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-17 18:29:53: foehnix.foehnix_filter: Applied limit-filter [90.0 270.0] to key dd_crest\n",
      "2019-01-17 18:29:53: foehnix.foehnix_filter: Applied limit-filter [43.0 223.0] to key dd\n",
      "2019-01-17 18:29:53: foehnix.foehnix: Calling Foehnix.unreg_fit\n",
      "2019-01-17 18:29:53: foehnix.foehnix: EM iteration 0/100, ll =  -42834.74\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 1/100, ll =  -41367.52\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 2/100, ll =  -40927.69\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 3/100, ll =  -40766.27\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 4/100, ll =  -40692.78\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 5/100, ll =  -40657.15\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 6/100, ll =  -40640.87\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 7/100, ll =  -40634.98\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 8/100, ll =  -40634.65\n",
      "2019-01-17 18:29:54: foehnix.foehnix: EM iteration 9/100, ll =  -40637.14\n",
      "2019-01-17 18:29:54: foehnix.foehnix: Estimation finished, create final object.\n"
     ]
    }
   ],
   "source": [
    "mod =  foehnix.Foehnix('diff_t', train ,concomitant='ff', filter_method=ddfilter, switch=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of observations (total)    71346\n",
      "Removed due to missing values     10187 (14.3 percent)\n",
      "Outside defined wind sector       43539 (61.0 percent)\n",
      "Used for classification           17620 (24.7 percent)\n",
      "\n",
      "Climatological foehn occurance 13.38 percent (on n = 61159)\n",
      "Mean foehn probability 13.23 percent (on n = 61159)\n",
      "\n",
      "Log-likelihood: -40634.7, 6 effective degrees of freedom\n",
      "Corresponding AIC = 81281.3, BIC = 81328.0\n",
      "\n",
      "Number of EM iterations 9/100 (converged)\n",
      "Time required for model estimation: 0.8 seconds\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
